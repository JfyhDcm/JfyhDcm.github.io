<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>JfyhDcm's Blog - 蚊香蛙</title><meta name="author" content="JfyhDcm"><meta name="copyright" content="JfyhDcm"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="JfyhDcm&#39;s Blog">
<meta property="og:url" content="https://jfyhdcm.github.io/index.html">
<meta property="og:site_name" content="JfyhDcm&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jfyhdcm.github.io/img/ava.jpeg">
<meta property="article:author" content="JfyhDcm">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jfyhdcm.github.io/img/ava.jpeg"><link rel="shortcut icon" href="/img/dragon.png"><link rel="canonical" href="https://jfyhdcm.github.io/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'JfyhDcm\'s Blog',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2021-11-29 10:10:55'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/ava.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">18</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/bgPic.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">JfyhDcm's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/messageboard/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">JfyhDcm's Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/JfyhDcm" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:836439982@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP9:Mutilingual%20BERT/" title="李宏毅NLP9:Multilingual BERT">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP9:Multilingual BERT"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP9:Mutilingual%20BERT/" title="李宏毅NLP9:Multilingual BERT">李宏毅NLP9:Multilingual BERT</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-27T15:48:14.917Z" title="Created 2021-11-27 23:48:14">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">Multilingual BERT</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP8:GPT-3/" title="李宏毅NLP8:GPT-3">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP8:GPT-3"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP8:GPT-3/" title="李宏毅NLP8:GPT-3">李宏毅NLP8:GPT-3</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-27T05:24:17.075Z" title="Created 2021-11-27 13:24:17">2021-11-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">GPT-3

GPT-3的愿望就是为了：消灭掉Fine-tune步骤，一个Language Model解决所有的问题。这其实是人类的能力，比如一个人去参加英文四六级考试，对于不同的题型，都可以做出回答。
所以GPT-3的Model包括一个Task Description，用来说明要做的任务，然后就可以解题了，如下图所示：


但是这里的few-shot、one-shot、zero-shot和其原意不同，并不是在训练集里的。而是一种称为“In-context” 的Learning，这些信息都直接作为GPT-3的输入。


效果还不错。
但是GPT-3在预训练的时候犯了一个大问题，他忘记把各种实验数据集从预训练语料中删除了，但是影响不大。
</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/11/26/%E8%A6%81%E5%AD%A6%E7%9A%84%E5%86%85%E5%AE%B9/" title="No title">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/26/%E8%A6%81%E5%AD%A6%E7%9A%84%E5%86%85%E5%AE%B9/" title="No title">No title</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-26T13:21:34.626Z" title="Created 2021-11-26 21:21:34">2021-11-26</time></span></div><div class="content">https://blog.csdn.net/u011412768/article/details/108015783 BERT的结构和原理实现
Bert的pool层是咋回事？
</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/11/23/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85BERT%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/" title="李宏毅BERT和他的朋友们">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅BERT和他的朋友们"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/23/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85BERT%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/" title="李宏毅BERT和他的朋友们">李宏毅BERT和他的朋友们</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-23T12:13:30.627Z" title="Created 2021-11-23 20:13:30">2021-11-23</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">BERT和他的朋友们过去的历史One-hot编码，缺点是：词意相近的词在one-hot中并没有体现出“相近”


使用word embedding，将one-hot和word class联合起来做投影，增加了语义信息


但是还是解决不了一词多义的情况。
现在的Model可以做到每一个word token（一个词的不同意思）有一个word embedding,而不是一个word type（同一个词）共用所有word embedding。所以被称为contextualized word embedding.
ELMOEmbeddings from Language Model

RNN based language model (trained from lots of sentences)



EMLO Model是使用RNN网络的，吃“&lt;BOS&gt;”预测“潮水”，吃“潮水”预测“退了”。但是这样只能从前预测后，所以改进成双向的。


双向的网络完成后，还可以增加RNN的深度，这样就会形成很多embedding（红色方框里的部分，可以看出一个双向RNN构成的embeddin ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/11/20/%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83%E5%92%8CBeta%E5%88%86%E5%B8%83/" title="No title">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/20/%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83%E5%92%8CBeta%E5%88%86%E5%B8%83/" title="No title">No title</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-20T10:43:42.695Z" title="Created 2021-11-20 18:43:42">2021-11-20</time></span></div><div class="content">Beta分布：https://blog.csdn.net/a358463121/article/details/52562940
详细讲解：https://blog.csdn.net/guleileo/article/details/80971601
变分推断ELBO：https://blog.csdn.net/qy20115549/article/details/93074519
变分推断概率图：https://qianyang-hfut.blog.csdn.net/article/details/86644192
</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/11/12/%E4%BB%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E5%88%B0EM/" title="从极大似然到EM">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从极大似然到EM"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/12/%E4%BB%8E%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E5%88%B0EM/" title="从极大似然到EM">从极大似然到EM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-12T02:08:58.925Z" title="Created 2021-11-12 10:08:58">2021-11-12</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="content">从极大似然到EM极大似然估计https://zhuanlan.zhihu.com/p/26614750
EM算法https://zhuanlan.zhihu.com/p/40991784
理解：有一个隐式变量z和显式变量，让它们互相配合，达到和现在结果最一致的最大似然
E-step:求后验概率 M-step:最大化似然概率
先验概率和后验概率https://zhuanlan.zhihu.com/p/26464206
</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/11/11/CRF/" title="CRF">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CRF"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/11/CRF/" title="CRF">CRF</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-11T05:58:09.802Z" title="Created 2021-11-11 13:58:09">2021-11-11</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">CRF</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/11/05/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP6:NLP%20tasks/" title="李宏毅NLP6:NLP tasks">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP6:NLP tasks"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/11/05/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP6:NLP%20tasks/" title="李宏毅NLP6:NLP tasks">李宏毅NLP6:NLP tasks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-11-05T08:42:43.901Z" title="Created 2021-11-05 16:42:43">2021-11-05</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">NLP tasksChapter OneMutiple Sentence对于多个句子的输入，我们该怎么办？
第一种方法：两个句子分别用Model，然后把它们Integrate起来，Integrate的时候可以使用Attention，也就是这个句子生成时参考另外一个句子。


第二种方法：把两个句子中间加一个[SEP]分隔开，然后扔到一个Model中。


所有NLP Tasks：


POS TaggingPOS: Part of Speech
就是对一个句子进行词性标注


Word Segmentation例如：台湾大学简称台大
输出N继续输出，输出Y就分词。


Parsing即做句法分析


Coreference Resolution指代消解：是指找到文章中相同的代词指代的内容。比如“he”、“she”指代的意思。顾名思义就是将指代词消解。
Summarization
Extractive summarization: 用文章里的某些句子平凑成一个summary。

Abstractive summarization：从文章中学习到summary


Machine Tran ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/10/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP7:Bert/" title="李宏毅NLP7:Bert">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP7:Bert"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/10/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP7:Bert/" title="李宏毅NLP7:Bert">李宏毅NLP7:Bert</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-10-27T07:43:15.186Z" title="Created 2021-10-27 15:43:15">2021-10-27</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">BertChapter OneBert的思路：首先使用大量text生成（Pre-train）一种具有“读懂”人类语言的model，然后针对不同的NLP任务，使用微调Fine-tune。


科学家们将语言模型的名字命名成芝麻街里的人物（真的是生搬硬凑…）。




What is pre-train model？其实在Bert之前就有很多Pre-train模型，比如Word2Vector、GloVe等。
对于Word2Vector Pre-train模型，每输入一个Word都会返回一个向量，缺点就是对于处在不同上下文的同一个词，输出的结果WordEmbedding vector 是一样的，这样并不好。


英语中的Word是非常多的，想把所有的word都有对应的vector几乎是不可能的，而FastText模型可以读入字母来判断word含义。


鉴于中文的象形字，可以使用CNN进行识别。


Contextualized word embedding（上下文的，即可以分别同一个word的不同意思），比如Bert，它是首先观察整个上下文，再返回word 的vector。
而bert等模 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/10/25/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP1:Speech%20Recgnition/" title="李宏毅NLP1:Speech Recgnition">     <img class="post_bg" src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP1:Speech Recgnition"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/10/25/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP1:Speech%20Recgnition/" title="李宏毅NLP1:Speech Recgnition">李宏毅NLP1:Speech Recgnition</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2021-10-25T07:10:27.460Z" title="Created 2021-10-25 15:10:27">2021-10-25</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/NLP/">NLP</a></span></div><div class="content">Speech RecognitionChapter OneSpeech2TextSpeech: a sequence of vector (length T, dimension d)
Text: a sequence of token(length N, V different tokens)
Usually, T &gt; N 


So, what is this so-called “Token”?
Token= Phoneme（音素、音位）/Grapheme （字素、字母）/Morpheme（词素、形态素：意思的最小单位）/Words/ Bytes字节
Lexicon（词典、辞典）: word to phonemes


英文的字母超过26个，因为起码要包含空格，可能还包含标点符号。




语音辨识的大趋势：


Acoustic Feature

一般窗口（window）大小为25ms，采样得到1个frame。每次移动10ms，所以会有重复的部分，1s的语音可以得到100个frame。
对于16KHz的声音，25ms（1s=1000ms）一个sample，1s有400sa ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/ava.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">JfyhDcm</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">18</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">3</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/JfyhDcm"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/JfyhDcm" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:836439982@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">千金难买寸光阴</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP9:Mutilingual%20BERT/" title="李宏毅NLP9:Multilingual BERT"><img src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP9:Multilingual BERT"/></a><div class="content"><a class="title" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP9:Mutilingual%20BERT/" title="李宏毅NLP9:Multilingual BERT">李宏毅NLP9:Multilingual BERT</a><time datetime="2021-11-27T15:48:14.917Z" title="Created 2021-11-27 23:48:14">2021-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP8:GPT-3/" title="李宏毅NLP8:GPT-3"><img src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅NLP8:GPT-3"/></a><div class="content"><a class="title" href="/2021/11/27/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP8:GPT-3/" title="李宏毅NLP8:GPT-3">李宏毅NLP8:GPT-3</a><time datetime="2021-11-27T05:24:17.075Z" title="Created 2021-11-27 13:24:17">2021-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/11/26/%E8%A6%81%E5%AD%A6%E7%9A%84%E5%86%85%E5%AE%B9/" title="No title"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2021/11/26/%E8%A6%81%E5%AD%A6%E7%9A%84%E5%86%85%E5%AE%B9/" title="No title">No title</a><time datetime="2021-11-26T13:21:34.626Z" title="Created 2021-11-26 21:21:34">2021-11-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/11/23/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85BERT%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/" title="李宏毅BERT和他的朋友们"><img src="https://i.loli.net/2021/06/01/OSzsQUGD9CIeL2V.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="李宏毅BERT和他的朋友们"/></a><div class="content"><a class="title" href="/2021/11/23/%E6%9D%8E%E5%AE%8F%E6%AF%85NLP/%E6%9D%8E%E5%AE%8F%E6%AF%85BERT%E5%92%8C%E4%BB%96%E7%9A%84%E6%9C%8B%E5%8F%8B%E4%BB%AC/" title="李宏毅BERT和他的朋友们">李宏毅BERT和他的朋友们</a><time datetime="2021-11-23T12:13:30.627Z" title="Created 2021-11-23 20:13:30">2021-11-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/11/20/%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83%E5%92%8CBeta%E5%88%86%E5%B8%83/" title="No title"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="No title"/></a><div class="content"><a class="title" href="/2021/11/20/%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83%E5%92%8CBeta%E5%88%86%E5%B8%83/" title="No title">No title</a><time datetime="2021-11-20T10:43:42.695Z" title="Created 2021-11-20 18:43:42">2021-11-20</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/NLP/"><span class="card-category-list-name">NLP</span><span class="card-category-list-count">9</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">算法</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/BERT/" style="font-size: 1.1em; color: #999">BERT</a> <a href="/tags/Bert/" style="font-size: 1.37em; color: #99a4b2">Bert</a> <a href="/tags/CRF/" style="font-size: 1.1em; color: #999">CRF</a> <a href="/tags/ELMO/" style="font-size: 1.1em; color: #999">ELMO</a> <a href="/tags/EM/" style="font-size: 1.1em; color: #999">EM</a> <a href="/tags/GPT/" style="font-size: 1.1em; color: #999">GPT</a> <a href="/tags/HMM/" style="font-size: 1.1em; color: #999">HMM</a> <a href="/tags/LDA/" style="font-size: 1.1em; color: #999">LDA</a> <a href="/tags/LSA/" style="font-size: 1.1em; color: #999">LSA</a> <a href="/tags/NLP/" style="font-size: 1.1em; color: #999">NLP</a> <a href="/tags/PageRank/" style="font-size: 1.1em; color: #999">PageRank</a> <a href="/tags/SVD/" style="font-size: 1.1em; color: #999">SVD</a> <a href="/tags/Speech-Recognition/" style="font-size: 1.1em; color: #999">Speech Recognition</a> <a href="/tags/TF-IDF/" style="font-size: 1.1em; color: #999">TF-IDF</a> <a href="/tags/TextRank/" style="font-size: 1.1em; color: #999">TextRank</a> <a href="/tags/pLSA/" style="font-size: 1.1em; color: #999">pLSA</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 1.23em; color: #999ea6">动态规划</a> <a href="/tags/%E6%95%B0%E5%AD%A6/" style="font-size: 1.23em; color: #999ea6">数学</a> <a href="/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" style="font-size: 1.1em; color: #999">朴素贝叶斯</a> <a href="/tags/%E6%9D%8E%E5%AE%8F%E6%AF%85/" style="font-size: 1.5em; color: #99a9bf">李宏毅</a> <a href="/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6/" style="font-size: 1.1em; color: #999">极大似然</a> <a href="/tags/%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/" style="font-size: 1.1em; color: #999">背包问题</a> <a href="/tags/%E8%AF%8D%E5%90%91%E9%87%8F/" style="font-size: 1.23em; color: #999ea6">词向量</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">November 2021</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/10/"><span class="card-archive-list-date">October 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">June 2021</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">May 2021</span><span class="card-archive-list-count">1</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">18</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2021-11-29T02:10:55.187Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By JfyhDcm</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "月落乌啼霜满天，江枫渔火对愁眠,桃李春风一杯酒，江湖夜雨十年灯,休对故人思故国，且将新火试新茶，诗酒趁年华".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '月'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>